---
title: "RL Learning"
description: "Tracking my learning of RL and getting good (generally)"
slug: rl-learning date: "March 10, 2025"
categories: ["RL"]
keywords: ["RL"]
topic: "Neo Gap Semester"
---

# Introduction This outlines my work with learning RL and whether it's worth pursuing further.

## March 10, 2025

Started working on the OpenAI Spinning Up. Today I went through the section on Kinds of RL Algorithms, 
Policy Optimization, and then looked at some code that implements basic policy gradient methods. Worked through the math 
of each step to understand the derivation. 

Read DQN paper. Clever tricks implemented with the "experience replay" to update the network. ]

Met with Marcus to discuss why is this interesting and what will it lead to:
- My immediate conclusion of a "risk" would be attepmting to implement MuZero and beat the paper. This is a fine goal. However, need a few things to be true:
    - Feasible within a budget (likely $5k in modal credits is the upper bound)
    - Feasible within 1-2 months
    - Must be absolutely stoked on it. 
    - Is sufficiently risky and has some interesting outcome. 
- Think about why nothing much has come of MuZero after the paper. Talk to people! Is it worth learning more about RL if it's not going to lead anywhere? 
    - Cold outreach to everyone who wrote the paper.
    - Look at who's citing it recently. 
    - Who is making improvements? Where? 
    - DM Brad Porter on Slack. 


What do i need to do tomorrow? 
- Keep working on spinning up.
- Cold outreach to all the people above. 
- Figure out how feasible/risky is the MuZero/EfficientZero implementation (esp. w.r.t my time in SF, is it worth it? Is it sufficiently risky?)
- What problems can be solved with RL that are meaningful? 
    - [Testing Casual hypothesis through hierarchical RL](https://openreview.net/pdf?id=ZqNcJ8uuHT)

## March 11, 2025

Worked with Harry on a tech spech for something he's doing. To get there, I read these papers:
- Skimmed DeepSeek Prover.
- [REFACTOR](https://www.semanticscholar.org/reader/5e7999443d37916269db5ff758587335335ff75d) paper - Learning to extract theorems from proofs. 
- Google's [PAIRED](https://research.google/blog/paired-a-new-multi-agent-approach-for-adversarial-environment-generation/) blog post.
- STP: Self-play LLM theorem prover.

Did longest substring without repeating characters LC #3.

Talked with Pavla about thoughts moving forward. Conclusions:
- Keep working on spinning up. 
- Start reaching out to professors at UVA doing deep learning/RL. 
- Cold outreach to people who wrote the MuZero paper. 
- Keep writing. 

- [x] Standard architectures 
    - [x] Multi-layer perceptron - multi layer neural network: http://ufldl.stanford.edu/tutorial/supervised/MultiLayerNeuralNetworks/
    - [x] [Vanilla RNN](https://karpathy.github.io/2015/05/21/rnn-effectiveness/)
        - [ ] TODO: Need to review this code, both the 100-line gist and the larger implementation. 
    - [X] [LSTM](https://arxiv.org/abs/1503.04069)
- [x] GRU - Gated Recurrent Unit
- [x] CNNs / conv layers:
    - [x] https://colah.github.io/posts/2014-07-Conv-Nets-Modular/
    - [x] https://cs231n.github.io/convolutional-networks/
- [x] resnets:
    - [x] (alex net) https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf
    - [x] (resnet) https://arxiv.org/pdf/1512.03385
- [x] attention mechanisms + transformers
    - review attention mechanisms: https://nlp.seas.harvard.edu/2018/04/03/attention.html
- [x] regularizaiton methods
    - [x] weight decay
    - [x] dropout
- [x] normalization methods
    - [x] batch norm: https://arxiv.org/abs/1502.03167
    - [x] layer norm: https://arxiv.org/abs/1607.06450
    - [x] weight norm: https://arxiv.org/abs/1602.07868
- [ ] optimizers
    - [ ] Adam: https://arxiv.org/abs/1412.6980
    - [ ] SGD: http://ufldl.stanford.edu/tutorial/supervised/OptimizationStochasticGradientDescent/
- [ ] reparametrization trick (auto-encoding variational bayes)
    - [ ] Paper that implements it: https://arxiv.org/abs/1312.6114
    - [ ] Blog post: https://gregorygundersen.com/blog/2018/04/29/reparameterization/
        - [ ] Prerequisites:
            - [ ] Variational Inference: https://arxiv.org/pdf/1601.00670
            - [ ] Tutorial on variational autoencoders: https://arxiv.org/pdf/1606.05908
            - [ ] AlexNet: https://papers.nips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf


## March 12, 2025

Worked through backprop in the MLP article, along with following 3Blue1Brown's video. 
Did a demo of Hufflo to a ecomm community, led to lots of new customers. 

## March 13, 2025

Partner came so was out, working out of coffee shop. 

Read long blog post sent by Harry on [KL Divergence](https://blog.alexalemi.com/kl-is-all-you-need.html)
created smaller list of professors at UVA to reach out to. 
for each professor, have list of grad students to talk to.

## March 14, 2025 - Day off. 

## March 17

- Worked thorugh a review of variational inference
- Worked through VAESs and reparameterization trick, including (brief) derivations. 
- Read through [doc on CNNs](https://cs231n.github.io/convolutional-networks/)

## March 18

Spent all day cooking on [Savant](https://github.com/toni-akintola/savant-io).

## March 19

- Spent half the day cooking on Savant, the other half of the day finishing up vanilla rnn blog post by Karpathy. 


## March 20

- Morning at GTC, talked with Jensen. Got backt to the office at 3:00
- Spent the afternoon working on emails to professors & who to reach out to. 

### Email to Professors (general)

#### Email to [Shangton Zhang [(shangtong@virginia.edu)](https://shangtongzhang.github.io/)

##### Draft 1 - Shangon Zhang
 
TITLE: [e5274d52b4c6] Undergraduate Research Intern Inquiry

Hi Professor Zhang, 

I'm Charlie Meyer, an undergrad CS student at UVA. I'm away from Grounds taking a 
semester off on a fellowship through the [Neo Scholars](https://neo.com/scholars) program to explore my interests. 

I have a strong background in software engineering and full stack development, but throughout my fellowship, 
I've become increasingly curious about machine learning and reinforcement learning. I'm working through OpenAI's "Spinning Up" 
along wtih Sutton and Barto's Introduction to RL textbook, with my goal of returning to Grounds in the fall of 2025 having a strong
foundation in RL and the math that motivates it. 

Why I will be helpful for you: 
- I will be a part-time student for an entire year so I'm willing
- I have backgrounds in the industry in software engineering working in small/large teams. 
- I've served ML workloads with Ray. 
- I'm a fast learner. 

Why I care about RL:
- I care about the beauty of the cleanliness of RL, and I enjoy the math behind it. 
- There are lots of interesting problems in RL:
    - Working in noisy environments
    - Sample efficiency
    - Model-free RL (the MuZero paper was mind-blowing to me!)
- RL "feels" less hand-wavey than LM's. 

Also, I'd love to talk with you in person in addition to a Zoom call. 
I'll be returning to UVA on March 29-30th and would love to chat in person if you're interested. 

Thank you, 

- I have a lot to learn from you
- your research direction xyz
- what is cool shit your grad students are doing? 


##### Draft 2 - Shangton Zhang

Hi Professor Zhang, 

I'm Charlie Meyer, an undergrad CS student at UVA. I'm currently on a fellowship through the 
[Neo Scholars](https://neo.com/scholars) program and have spent my time away from Grounds exploring 
machine learning and reinforcement learning, and would love to intern for you. 

Why you would benefit from me:
- I will be part-time student for an entire year and willing to dedicate 40+ hours/week to research.
- I have this remaining semester with the fellowship, along with a summer to dedicate to spinning up in RL. 
- I have worked in small and large teams in the industry as a software engineer at 
[Principal Financial Group](https://www.principal.com/) and [Vercel](https://vercel.com).
- I've worked on various ML projects:
    - Fine-tuned diffusion models (worked with Rivanna).
    - Served ML workloads with Ray.
    - Completed simple RL experiments with OpenAI gymnasium. 

Qualitative skills:
- I'm a fast learner. 
- I have a strong foundation in math. 
- I'm curious and eager to explore research (prefer to move away from traditional SWE web/fullstack work).

What I'm working on to get up to speed:
- OpenAI's Spinning Up in RL.
- Sutton and Barto's Textbook (accompanied with your GitHub repo of the python replication).
- Building towards an implementation of AlphaZero. 

I'd love to chat over Zoom if you're interested to see if there's a good fit. I will also be returning to UVA on March 29-30th, so 
I'd also enjoy the opportunity to talk in person.

Thank you, 


##### Draft 3 - Shangton Zhang

Title: [e5274d52b4c6] Undergraduate Research Intern Inquiry

Hi Professor Zhang, 

I'm Charlie Meyer, an undergrad CS student at UVA. I'm on a fellowship away from Grounds through the [Neo Scholars](https://neo.com/scholars) program
which has allowed me to spend the past few months exploring my interests in machine learning and reinforcement learning. I want
to return to Grounds in the fall of 2025 and contribute to your research as an intern.

Why you'd benefit from me: 
- I'm willing to dedicate 40+ hours/week to research since I will be a part-time student for the entire year.
- I'm willing to spend the rest of my fellowship and summer spinning up in RL, working alongside you.
- I have experience in industry working as a software engineer 
at [Principal Financial Group](https://www.principal.com/) and [Vercel](https://vercel.com), so 
I can contribute without hand-holding.

Why me? 
- I'm curious to explore research in RL
- I am already up to speed with basics of RL and the math that motivates it. 
- I've already worked with ML/RL in the past: 
    - Fine-tuned diffusion models (on Rivanna).
    - Served ML workloads with Ray. 
    - Completed simple RL experiments with OpenAI gymnasium. 

What I'm working on to get up to speed:
- OpenAI's Spinning Up in RL.
- Sutton and Barto's Textbook (accompanied with your GitHub repo of the Python replication).
- Building towards an implementation of AlphaZero. 

I'd love to chat over Zoom if you're interested to see if there's a good fit. I will also be returning to UVA on March 29-30th, so 
I'd also enjoy the opportunity to talk in person.

Thank you,


##### Draft 4 - Shangton Zhang

Hi Professor Zhang, 

I'm Charlie Meyer, an undergrad CS student at UVA. I'm on a fellowship away from Grounds through the [Neo Scholars](https://neo.com/scholars) program
which has allowed me to spend the past few months exploring my interests in machine learning and reinforcement learning. I want
to return to Grounds in the fall of 2025 and contribute to your research as an intern.

Why you'd benefit from me?
- I will be a part-time student for an entire year and therefore will work incredibly hard on your research.
- I am willing to spend the rest of my fellowship and summer spinning up in RL, working alongside you.
- I have experience in industry working as a software engineer 
at [Principal Financial Group](https://www.principal.com/) and [Vercel](https://vercel.com), so 
I can contribute without hand-holding.

Why pick me?
- I'm interested in Amir Moeini's work with mathematical benchmarking. I've recently explored automated theorem proving (ATP) which 
has had a lot of movement recently, including AlphaProof. Most labs are focusing on LLM-based approaches (DeepSeek with DeepSeek-Math, Harmonic.ai), but 
few besides DeepMind are exploring RL-based approaches. In early 2025, labs have reached SOTA on MiniF2F using MCTS and/or Best-First Tree Search approaches, 
so I believe there's opportunity to move quickly and use interesting RL techniques for ATP. I'm incredibly interested in mathematical superintelligence, 
and it seems to align with Amir and your research direction. 
- I've worked with ML/RL in the past:
    - Fine-tuned diffusion models (on Rivanna).
    - Served ML workloads with Ray. 
    - Completed simple RL experiments with OpenAI gymnasium. 
- I'm a fast learner.

What I'm working on to get up to speed?
- OpenAI's Spinning Up in RL.
- Sutton and Barto's Textbook (accompanied with your GitHub repo of the Python replication).

I'd love to chat over Zoom if you're interested to see if there's a good fit. I will also be returning to UVA on March 29-30th, so 
I'd also enjoy the opportunity to talk in person.


### [Email to Aidong Zhang (aidong@virginia.edu)](https://www.cs.virginia.edu/~az9eg/website/home.html)

#### Draft 1

Hi Professor Zhang, 

I'm Charlie Meyer, an undergrad CS student at UVA. I'm on a fellowship through the 
[Neo Scholars](https://neo.com/scholars) program and have spent the past few months exploring my interests in machine learning, and
I'm reaching out to see if there is an opportunity for me to intern for you. I'm partiularly interested in your work in federated learning. 

I saw on your website that you're looking for PhD students, but I'm wondering if there's an opporuntity for an undegraduate to intern. 

Why I'd be useful for you:
- I'm going to be a part-time student for an entire year, so I'm willing to dedicate 40+ hours/week to research. 
- I have experience in industry working as a software engineer and am able to contribute without hand-holding. 
- I will be spending the rest of my fellowship and summer spinning up in machine learning, and am willing to work alongside you to 
get up to speed so we can work together in F2025. 

Why you should talk to me:
- I'm curious about your work in federated learning. 
- I have experience in ML/RL:
    - Served ML workloads with Ray. 
    - Finetuned diffusion models (on Rivanna).
- I'm a fast learner.

I'd love to chat over Zoom if you're interested to see if there's a good fit. I will also be returning to UVA on March 29-30th, so 
I'd also enjoy the opportunity to talk in person.

Thank you,

### Email to Chen-Yu Wei [(chenyu.wei@virginia.edu)](https://bahh723.github.io/)


#### Draft 1

Hi Professor Wei, 

I'm Charlie Meyer, an undergrad CS student at UVA. I'm on a fellowship through the 
[Neo Scholars](https://neo.com/scholars) program and have spent the past few months exploring my interests in machine learning and reinforcement learning, and
I'm reaching out to see if there is an opportunity for me to intern for you. Although I have little experience in ML/RL, I'm incredibly curious and eager 
to learn with your guidance. 

Why I'd be useful for you:
- I will be a part-time student for an entire year, so I'm able to work incredibly hard on supporting your research. 
- I have experience in industry working as a software engineer and am able to spin-up quickly without hand-holding. 
    - Worked at [Principal Financial Group](https://www.principal.com/) scaling AWS infrastructure as code, and [Scenthound](https://www.scenthound.com/) as a full-stack developer. 
    - Launched multiple SaaS products (https://www.hufflo.com, https://www.simpletext.dev) in 2-week sprints. 
    - Will work at [Vercel](https://vercel.com) in SF this summer. 
- I have expereince in ML:
    - Served ML workloads with Ray. 
    - Finetuned diffusion models (on Rivanna).
    - Completed simple RL experiments with OpenAI gymnasium. 

What I'm interested in in your lab:
- I was incredibly impressed by the work on the regret bound you created in adversarial linear MDPs, along with the work that built
upon DEC for a hybrid model type. I would love to talk with Haolin about their work!
- I saw that Kingsley is working on RLHF methods with Haolin. I've read recent surveys about LM persuasion and papers guaranteeing LM truthfulness within certian bounds, and am 
interested in the application of RLHF methods. 
- As mentioned on your website, I'm also interested in practical applications of RL. I'd love to talk about an emerging use case for RL: automated theorem proving. 
With improvements in synthetic data, labs starting to make progress in theorem proving (DeepMind with AlphaProof, DeepSeek with DeepSeek-Math and DeepSeek-Prove), and LLMs improved ability to generate Lean 4, I think there's a great opportunity to use RL for 
mathematical superintelligence (rather than LLM-based approaches).

What I'm working on to get up to speed:
- OpenAI's Spinning Up in RL.
- Sutton and Barto's Textbook (accompanied with your GitHub repo of the python replication).

I'd love to work with you throughout the end of my fellowship, throughout the summer, and then into the fall of 2025 if you are interested. 
Let me know if you'd like to chat over Zoom to see if there's a good fit. I will also be returning to UVA on March 29-30th, so 
I'd also enjoy the opportunity to talk in person.

Thank you,

### Email/Form to Yu Meng [(yumeng5@virginia.edu)](https://yumeng5.github.io/)

#### Google Form

( Anything else you'd like to mention section )

Hey! 

I followed up in an email explaining who I am, but this is a brief overview. I'm Charlie Meyer, currently on a fellowship gap-semester program through the Neo Scholars program (https://neo.com/scholars). Throughout this fellowship I've become incredibly passionate about ML and LM safety and want to dedicate the remaining time I have at UVA to research. I'm looking to intern for you if you see a fit. Although I have little experience with AI/ML research, I'm incredibly curious and eager to learn with your guidance. 

I'm interested in you and your PhD students' work with InstructRAG & synthetic data generation. InstructRAG provides interesting applications for synthetic data generation, and its improvement of RAG performance is impressive. Having built RAG systems in the past, I'd love to discuss this work and applications to creating PLMs. I'm particularly interested in the use case of synthetic data generation for generating Lean 4, as this can contribute to automated theorem proving - a new space with that needs high-quality data. Labs have pushed many math benchmarks including DeepSeek (DeepSeek-Prove) and DeepMind (AlphaProof), and this space is an interesting application of synthetic data. 

I will be beneficial for you because:
- Since I'm going to be a part-time student all of next year, I'm willing to dedicate a significant amount of time to supporting your research, along with spending the remaining time of my fellowship and summer to get up-to-speed with your work.  
- I have industry experience working at 3 different companies (ScentHound, Principal Financial Group, and Vercel) along with other startup ventures and am able to work quickly in new environments with minimal hand-holding. 
- I'm a very fast learner. 

Thank you for your consideration!


#### Draft 1

Hi Professor Meng, 

I've filled out the Google Form on your website, but I'm also reaching out to elaborate on my application to provide more context. 

## March 24

- Wrote emails to 3 professors. 
- Read through all Streams for MATS and picked people I'd apply to.

## March 25:

### Jason Gross & Rajashree Agrawal Application

#### Q1 What's your experience w/software development using AI?

AI-Powered Coding Tools I've used:
- Cursor (cursor.com)
- Windsurf (codeium.com/windsurf)
- Claude Code (docs.anthropic.com/en/docs/agents-and-tools/claude-code)
- Copilot (github.com/features/copilot)

Other:
- Used preview of Devin (cognition.ai)
- Compared Cursor vs. Windsurf vs. Claude Code to build the same project using only prompts
- Built agentic tooling in conversational chatbots

#### Q2 What's the most technically impressive project you've built? 

In a two-week sprint I built simpletext.dev, a SMS and OTP provider. This project was a large undertaking becuase of the systems challenging of providing high-availability,  and fraud detection challenges to ensure I follow legal constraints from 10DLC phone numbers. From the systems perspective, this meant ensuring high availability and durability. This required me to build multi-AZ failover for routing, databases, and APIs, along with periodic backups, logging, and observability across the stack to catch errors. The crux of simpletext was that unlike other SMS providers that require you to register your company for a 10DLC phone number, simpletext assumes all liability of every text message sent - and therefore any message sent by a simpletext customer is my responsibility. To ensure that I followed wireless carriers' regulations to cut down on spam, I implemented fraud-detection systems, flagging potential spam/scam messages and alerting me of accounts using my service for suspicious purposes. 

OR TALK ABOUT HYMN AND DIFFUSION? 

Right before ChatGPT came out, I built a text-to-audio service targeted at music producers. This service turned text queries like "a simple drum progression at 127 BPM" into audio samples that users can use with their music. Initially, the ervice used Riffusion (an open-source model), but because we were focused on generating _samples_ rather than music, This required fine-tuing stable diffusion to generate images  5-second clips of audio using spectograms (visual representations of audio) which were then converted into downloadable audio files. This was also a difficult systems challenge, as our service required hosted a queuing system, the diffusion pipeline and the website on kubernetes, along with managing observability, object storage, and other frontend requirements for a high-quality user experience.

#### What is a specific fact about your worldview/aesthetics/skills that makes you want to work on this project? Alternatively, this is a space to share whatever else seems relevant to your application.

Most technological innovations are underpinned by mathematical breakthroughs years or decades before. I believe that mathematical superinteligence is necessary for the development of GSAI, and doing so through automated theorem proving (ATP) seems to be the most tractable way to achieve this. By contributing to this problem, I am immediately contributing to scientific progress more than I ever have before in my life. Moreover, this problem has larger implications than just having bug-free code - if a mathematically superintelligent system can prove unsolved conjectures, this impacts cryptography, physics, algorithm design, and economics drastically. The "what if this works" of ATP is why I gravitate to contributing to this problem.

I think there are interesting sub-problems to explore, including:
- RL-based (instead of LM-based approaches):
	- How to get a "conjecture proposer" to propose meaningful conjectures to solve? 
	- How do you evaluate the "quality" of a proof? 
	- Given a corpus of theorems (mathlib, for example), how can we ensure proposers/solvers use the best theorems at their disposal? 
- Evaluating fine-tuning vs few-shot vs. CORPORA-based approaches.

I want to be candid that I have minimal ML experience only through small side-projects and one month of self-study, and no professional expereince. I am on a gap-semester from college through the Neo Scholars program and have spent the past month ramping up in machine learning, having previously spent most of my time building SaaS products. I am inexperienced but incredibly curious, obsessive about understanding ML systems, and enjoy how I am being pushed into an uncomfortable space, away from my product-oriented past. 

#### What are 1-3 pieces of evidence that you'd be able to do good research in the stream? 

- Because of my fullstack experience, I'm accustomed to shipping incredibly quickly and iterating on a well-scoped hypothesis quickly for immediate feedback. I will bring this to a research environment. 
- In the past month, I've become comfortable learning the process of moving from paper to implementation. I'm comfortable working independently and building from first principles. 

### Joshua Clyner - evaluation and control methods application

#### Question 1 - Conditional on scheming / deceptive alignment arising naturally (i.e. not in a model organism / demo), how capable do you think models will be when it first emerges, and why? (250 words max)

When deceptive alignment (DA) arises naturally, models will be capable of manipulating multiple humans over long timespans. They will be using humans to achieve long-term goals without their knowledge. 

outline:
- Overarching idea: When DA arises naturally, models will be able to 
	- construct larger, organized plans over a long period of time. i.e. overcoming test-time compute such that it can reason over long-horizon projects. This will allow models to 
	- deceive many people at once, as a part of this larger plan (deception across individuals in pursuit of a larger goal).
	- situational awareness - it knows it's being used & deployed to millions of people, and therefore adjusts its strategies accordingly. it adjusts its outputs with consideration of the actions of other models.  
	- Implicit coordination - models share latent knowledge wherein they implicitly "coordinate" to converge on similar solutions without explicit interaction. This is different than explicit side-channel-esque communication. 

###### Question 1 Response

When deceptive alignment (DA) arises, models will have achieved or exceeded general intelligence according to OpenAI's definition. At this level, three significant improvements will manifest. First, models can plan using orders of magnitude of tokens larger than the current test-time compute capabilities, allowing models to formulate complex, multi-step, and long-horizon plans. Second, these plans will unfold gradually, evading immediate human detection. Finally, multiple instances of these models will implicitly coordinate through shared latent knowledge by recognizing that similar models will also independently pursue aligned goals without explicit communication to the user. This differs from current research that demonstrates LMs attempting to explicitly create side-channels towards a goal of acquiring resources (Anthropic's alignment faking or evidence of LMs sandbagging). Once DA arises naturally, models will craft long-term goals predicated on the understanding that all other models will do the same; therefore, rather than attempting a backdoor, models will create effective and widespread deceptive influence, undetectable by humans. This will manifest in more subtle but sinister ways, including influencing the general population's political beliefs in favor of candidates less concerned with AI safety policies or impacting market decisions on a mass scale. 

### Nicholas Carlini 

#### Notes on what he fucks with

- Can we scale attacks? Make them better than ones in the literature? 
- Study the robustness of a system that uses llms (worst case, create that system)
- construct cybersecurity evals that are meaningful.

- Papers he's written summary:
	- polynomial time extracting weights of a model in "hard label" (most-likely class label only scenario). 
	- stealing part of a production language model - "how much info can we gain from a production language model by querying its api?". 

### Blurb to Haize for Connor. 

### Requirements

Haize Labs haizes LLMs at scale. We are the robustness layer eliminating the risk of using language models in any setting. To prevent these systems from failing, we preemptively discover all the ways in which they can fail and continuously eliminate them in deployment.

We are looking for Research Interns to help us to develop fundamental safety tooling for LLMs. Your work will not only set the standard both in terms of research, but also in terms of how LLMs are tested, verified, and applied across customers, companies, and industries. You will directly influence how the world responsibly uses LLMs.

Responsibilities

Work directly with customers to adapt our core R&D for different domains.
Build out core infra, cloud tooling, and UX around our algorithms.
Deliver a delightful human-in-the-loop product experience.
Ship tools that are used by developers across the world. 
Qualifications

Experience with ML in an applied setting.
Strong open source presence or strong track record of software engineering projects and employment.
Can ramp up very quickly on understanding our research.
Love to break things, i.e. have a “stick it to the Man” attitude.

### Blurb 

Charlie is a Neo Scholar on a gap semester from college (organized by Neo) with a fullstack background, using the gap semester to spin up on ML/AI alignment. He has experience in product/software (interned at 3 companies, potentially at Vercel this summer) and has shipped dev tools, built cloud infra as code, and has UI/UX experience. Although he's new to ML and has no professional applied ML experience, he's incredibly curious, obsessive about understanding ML systems, and enjoys the uncomfortability of ramping up on new research. He's open to working in the summer/fall 2025, or around whatever timetable is suitable.


## April 1

Worked with harry a bit. 

## April 2

conversations with vercel & two uva researchers. Vercel convo went meh, seems like they don't have much ML-based work in Self, uva researchers both fucked with me heavy.



